{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57knM8jrYZ2t"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eirasf/GCED-AA3/blob/main/lab7/lab7.ipynb)\n",
    "\n",
    "# Práctica 7: Autoaprendizaje\n",
    "\n",
    "## Pre-requisitos\n",
    "\n",
    "### Instalar paquetes\n",
    "\n",
    "Si la práctica requiere algún paquete de Python, habrá que incluir una celda en la que se instalen. Si usamos un paquete que se ha utilizado en prácticas anteriores, podríamos dar por supuesto que está instalado pero no cuesta nada satisfacer todas las dependencias en la propia práctica para reducir las dependencias entre ellas.\n",
    "\n",
    "### NOTA: En <font color='red'>Google Colab</font> hay que instalar los paquetes EN CADA EJECUCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkaimNJfYZ2w"
   },
   "outputs": [],
   "source": [
    "# Ejemplo de instalación de tensorflow 2.0\n",
    "#%tensorflow_version 2.x\n",
    "# !pip3 install tensorflow  # NECESARIO SOLO SI SE EJECUTA EN LOCAL\n",
    "import tensorflow as tf\n",
    "\n",
    "# Hacemos los imports que sean necesarios\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOch-CnwQttl"
   },
   "source": [
    "# Autoaprendizaje sobre Fashion-MNIST\n",
    "\n",
    "Lo primero que tenemos que hacer es cargar el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gXdWDBIEKel"
   },
   "outputs": [],
   "source": [
    "labeled_data = 0.05 # Vamos a usar el etiquetado de sólo el 5% de los datos\n",
    "np.random.seed(42)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "indexes = np.arange(len(x_train))\n",
    "np.random.shuffle(indexes)\n",
    "ntrain_data = int(labeled_data*len(x_train))\n",
    "unlabeled_train = x_train[indexes[ntrain_data:]]\n",
    "x_train = x_train[indexes[:ntrain_data]\n",
    "y_train = y_train[indexes[:ntrain_data]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XsZIqV8TmSc"
   },
   "outputs": [],
   "source": [
    "# TODO: Haz el preprocesado que necesites aquí (si lo necesitas)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkaCDOGapMyl"
   },
   "source": [
    "## Función de autoaprendizaje\n",
    "\n",
    "Vamos a crear nuestra propia función de autoaprendizaje. Para ello, vamos a utilizar el siguiente pseudocódigo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qBChtzdTZU9"
   },
   "source": [
    "\n",
    "\n",
    "**self_training** *(model, x_train, y_train, unlabeled_data, thresh, train_epochs)*\n",
    "\n",
    "1. $train\\_data, train\\_label \\leftarrow x\\_train, y\\_train$\n",
    "1. **Desde** $n = 1 .. train\\_epochs$ **hacer**\n",
    "\t1. Entrena el *model* usando las variables *train\\_data* y *train\\_label* \n",
    "\t2. $y\\_pred \\leftarrow model(unlabeled\\_data)$\n",
    "  \n",
    "  3. $y\\_class, y\\_value \\leftarrow $ Clase ganadora en *y_pred* con su valor\n",
    "\n",
    "  4. $train\\_data, train\\_label \\leftarrow x\\_train, y\\_train$\n",
    "  \n",
    "  5. **Para cada elemento** (x_u, y_c, y_v) **de la tupla** (unlabeled_data, y_class, y_value) \n",
    "\t  1. **Si** $y\\_v > thresh$ **entonces**\n",
    "\t\t\n",
    "        1. Añadimos $x\\_u$ e $y\\_c$ a train\\_data y train\\_label, respectivamente.\n",
    "\n",
    "4. Devolvemos el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqT2nuCspfE_"
   },
   "source": [
    "<font color='red'>NOTA:</font> para entrenar (y predecir) vamos a utilizar los modelos de Sklearn. Familiarízate con las funciones [fit](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.fit), [predict](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict), [predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict_proba) y [score](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xjcLa21EKen"
   },
   "outputs": [],
   "source": [
    "# TODO: implementa el algoritmo self_training tal y como viene en el pseudocódigo. Las variables extra son para epara visualización de resultados\n",
    "\n",
    "def self_training(model_func, x_train, y_train, unlabeled_data, x_test, y_test, thresh=0.5, train_epochs=3):\n",
    "    train_data = x_train.copy()\n",
    "    train_label = y_train.copy()\n",
    "    for i in range(train_epochs):\n",
    "        model = model_func()\n",
    "        None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjFXe6EiYfRg"
   },
   "source": [
    "### Entrenamos nuestro clasificador\n",
    "\n",
    "Usa lo hecho anteriormente para entrenar tu clasificador de una manera semi-supervisada. Utiliza para ello el [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) de sklearn (vigila el parámetro probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNC1s2Wmqx4x"
   },
   "outputs": [],
   "source": [
    "# Define la función para llamar al SVM\n",
    "from sklearn.svm import SVC\n",
    "model_func = lambda: SVC(kernel='linear', probability=True, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hN2zd3DEYnKI"
   },
   "outputs": [],
   "source": [
    "# TODO: Entrena tu clasificador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbUKp14pPsrp"
   },
   "source": [
    "## Mejorando el código\n",
    "\n",
    "Tal como hemos visto en clase de teoría, este código puede ser mejorado de varias maneras:\n",
    "\n",
    "  1. **Asignar más peso a las variables etiquetadas**.\n",
    "  1. **Asignar un peso en función de la certeza de la predicción en las variables sin etiquetar**.\n",
    "\n",
    "### TRABAJO: Modifica la función self_training para tener en cuenta todos los puntos mencionados anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7eF_9LMeZ2J2"
   },
   "outputs": [],
   "source": [
    "# TODO: reescribe la función self_training para incorporar las mejoras mencionadas anteriormente\n",
    "\n",
    "def self_training_v2(model_func, x_train, y_train, unlabeled_data, x_test, y_test, thresh=0.8, train_epochs=3):\n",
    "    None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbqC0inexwHp"
   },
   "outputs": [],
   "source": [
    "# TODO: Entrena tu clasificador\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_knU62FdYJKn"
   },
   "source": [
    "### Creamos nuestro clasificador en Tensorflow\n",
    "\n",
    "Ya deberías de ser capaz de realizar este trabajo con muy poca ayuda. El diseño del clasificador es libre (capas densas, convolucionales, ...), puedes crearlo como quieras. Lo único que tenemos que tener en cuenta es que tenemos que encapsular nuestro modelo en una clase cuyas funciones tengan el mismo nombre (y los mismos parámetros) que las existentes en sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dG31TKIraE7r"
   },
   "outputs": [],
   "source": [
    "# TODO: crea tu propio clasificador\n",
    "\n",
    "class MiClasificador:\n",
    "\n",
    "    def __init__(self):\n",
    "        # TODO : define el modelo\n",
    "        self.model = None\n",
    "        # TODO: crea el optimizador\n",
    "        None\n",
    "        # TODO: compila el modelo\n",
    "        self.model.compile(\n",
    "            loss=None,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO: devuelve la clase ganadora\n",
    "        pass\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # TODO: devuelve las probabilidades de cada clase\n",
    "        pass\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        # TODO: devuelve el accuracy del clasificador\n",
    "        pass\n",
    "\n",
    "    def __del__(self):\n",
    "        del self.model\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBdkgibORzyh"
   },
   "source": [
    "### Entrenando el modelo\n",
    "\n",
    "Crea una función que nos permita crear el modelo en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--x-RSJbeUdB"
   },
   "outputs": [],
   "source": [
    "# TODO: Entrena el modelo\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnqgYFqiSUSt"
   },
   "source": [
    "# ¡ENHORABUENA! Has completado la práctica de auto-aprendizaje.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7_autoaprendizaje.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
