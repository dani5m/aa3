{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57knM8jrYZ2t"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eirasf/GCED-AA3/blob/main/lab7/lab7.ipynb)\n",
    "\n",
    "# Práctica 7: Autoaprendizaje\n",
    "\n",
    "## Pre-requisitos\n",
    "\n",
    "### Instalar paquetes\n",
    "\n",
    "Si la práctica requiere algún paquete de Python, habrá que incluir una celda en la que se instalen. Si usamos un paquete que se ha utilizado en prácticas anteriores, podríamos dar por supuesto que está instalado pero no cuesta nada satisfacer todas las dependencias en la propia práctica para reducir las dependencias entre ellas.\n",
    "\n",
    "### NOTA: En <font color='red'>Google Colab</font> hay que instalar los paquetes EN CADA EJECUCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkaimNJfYZ2w"
   },
   "outputs": [],
   "source": [
    "# Ejemplo de instalación de tensorflow 2.0\n",
    "#%tensorflow_version 2.x\n",
    "# !pip3 install tensorflow  # NECESARIO SOLO SI SE EJECUTA EN LOCAL\n",
    "import tensorflow as tf\n",
    "\n",
    "# Hacemos los imports que sean necesarios\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOch-CnwQttl"
   },
   "source": [
    "# Autoaprendizaje sobre Fashion-MNIST\n",
    "\n",
    "Lo primero que tenemos que hacer es cargar el dataset. Tomaremos el 5% de los datos como etiquetados (`x_train` e `y_train`) y el resto como no etiquetados (`unlabeled_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gXdWDBIEKel"
   },
   "outputs": [],
   "source": [
    "labeled_data = 0.05 # Vamos a usar el etiquetado de sólo el 5% de los datos\n",
    "np.random.seed(42)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "indexes = np.arange(len(x_train))\n",
    "np.random.shuffle(indexes)\n",
    "ntrain_data = int(labeled_data*len(x_train))\n",
    "unlabeled_train = x_train[indexes[ntrain_data:]]\n",
    "x_train = x_train[indexes[:ntrain_data]]\n",
    "y_train = y_train[indexes[:ntrain_data]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XsZIqV8TmSc"
   },
   "outputs": [],
   "source": [
    "# TODO: Haz el preprocesado que necesites aquí (Vuelve sobre esta celda tras estudiar las posteriores)\n",
    "# Asegúrate de tener los shapes apropiados y de que las variables se representen de una manera que el modelo pueda predecirlas.\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkaCDOGapMyl"
   },
   "source": [
    "## Función de autoaprendizaje\n",
    "\n",
    "Vamos a crear nuestra propia función de autoaprendizaje. La idea es comenzar aprendiendo un modelo para los datos etiquetados y predecir con ese modelo los datos sin etiquetar. De dichas predicciones, tomaremos aquellas en las que el modelo tiene mayor confianza (cuya probabilidad exceda un umbral `thresh`) y las añadiremos al conjunto de datos etiquetados. Repetiremos el proceso un número predeterminado de veces `train_epochs`.\n",
    "\n",
    "El pseudocódigo es el siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qBChtzdTZU9"
   },
   "source": [
    "\n",
    "\n",
    "**self_training** *(model, x_train, y_train, unlabeled_data, thresh, train_epochs)*\n",
    "\n",
    "1. $train\\_data, train\\_label \\leftarrow x\\_train, y\\_train$\n",
    "1. **Desde** $n = 1 .. train\\_epochs$ **hacer**\n",
    "    1. Instancia un nuevo *model* y entrénalo usando las variables *train\\_data* y *train\\_label* \n",
    "    2. $y\\_pred \\leftarrow model(unlabeled\\_data)$\n",
    "    3. $y\\_class, y\\_value \\leftarrow $ Clase ganadora en *y_pred* con su valor\n",
    "    4. $train\\_data, train\\_label \\leftarrow x\\_train, y\\_train$\n",
    "    5. **Para cada elemento** (x_u, y_c, y_v) **de la tupla** (unlabeled_data, y_class, y_value) \n",
    "        1. **Si** $y\\_v > thresh$ **entonces**\n",
    "            1. Añadimos $x\\_u$ e $y\\_c$ a train\\_data y train\\_label, respectivamente.\n",
    "4. Devolvemos el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqT2nuCspfE_"
   },
   "source": [
    "La función asume que `model_creator` es una función sin parámetros que instancia un modelo de Sklearn que, por tanto, cuenta con las funciones [fit](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.fit), [predict](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict), [predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict_proba) y [score](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.score). Consulta la documentación para identificar cuál te es útil en cada momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xjcLa21EKen"
   },
   "outputs": [],
   "source": [
    "# TODO: Implementa el algoritmo self_training tal y como viene en el pseudocódigo.\n",
    "# TODO: Imprime en cada epoch la precisión y el número de elementos en el conjunto etiquetado,\n",
    "\n",
    "def self_training(model_creator, x_train, y_train, unlabeled_data, x_test, y_test, thresh=0.5, train_epochs=3):\n",
    "    train_data = x_train.copy() # Copiamos los conjuntos de datos para no modificar los originales\n",
    "    train_label = y_train.copy()\n",
    "    for i in range(train_epochs):\n",
    "        model = model_creator()\n",
    "        #TODO Completa el algoritmo siguiendo el pseudocódigo\n",
    "        None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjFXe6EiYfRg"
   },
   "source": [
    "### Entrenamos nuestro clasificador\n",
    "\n",
    "Usa lo hecho anteriormente para entrenar tu clasificador de una manera semi-supervisada. Utiliza para ello el [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) de sklearn (vigila el parámetro probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNC1s2Wmqx4x"
   },
   "outputs": [],
   "source": [
    "# Define la función para llamar al SVM\n",
    "from sklearn.svm import SVC\n",
    "model_func = lambda: SVC(kernel='linear', probability=True, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hN2zd3DEYnKI"
   },
   "outputs": [],
   "source": [
    "# TODO: Entrena tu clasificador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbUKp14pPsrp"
   },
   "source": [
    "## Mejorando el código\n",
    "\n",
    "Tal como hemos visto en clase de teoría, este código puede ser mejorado de varias maneras:\n",
    "\n",
    "  1. **Asignar más peso a las variables etiquetadas**.\n",
    "  1. **Asignar un peso en función de la certeza de la predicción en las variables sin etiquetar**.\n",
    "\n",
    "### TRABAJO: Modifica la función self_training para tener en cuenta todos los puntos mencionados anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7eF_9LMeZ2J2"
   },
   "outputs": [],
   "source": [
    "# TODO: reescribe la función self_training para incorporar las mejoras mencionadas anteriormente\n",
    "\n",
    "def self_training_v2(model_creator, x_train, y_train, unlabeled_data, x_test, y_test, thresh=0.8, train_epochs=3):\n",
    "    None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbqC0inexwHp"
   },
   "outputs": [],
   "source": [
    "# TODO: Entrena tu clasificador\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_knU62FdYJKn"
   },
   "source": [
    "### Creamos nuestro clasificador en Tensorflow\n",
    "\n",
    "A continuación crearemos nuestro propio modelo en TensorFlow pero asegurándonos que tiene los métodos de la API de `sklearn` que se utilizan en `self_training`. Ya deberías de ser capaz de realizar este trabajo con muy poca ayuda. El diseño del clasificador es libre (capas densas, convolucionales, ...), puedes crearlo como quieras. Lo único que tenemos que tener en cuenta es que tenemos que encapsular nuestro modelo en una clase cuyas funciones tengan el mismo nombre (y los mismos parámetros) que las existentes en sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dG31TKIraE7r"
   },
   "outputs": [],
   "source": [
    "# TODO: crea tu propio clasificador\n",
    "\n",
    "class MiClasificador:\n",
    "\n",
    "    def __init__(self, optimizer):\n",
    "        # TODO : define el modelo\n",
    "        self.model = None\n",
    "        # TODO: crea el optimizador\n",
    "        None\n",
    "        # TODO: compila el modelo\n",
    "        self.model.compile(\n",
    "            loss=None,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO: devuelve la clase ganadora\n",
    "        pass\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # TODO: devuelve las probabilidades de cada clase\n",
    "        pass\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        # TODO: devuelve el accuracy del clasificador\n",
    "        pass\n",
    "\n",
    "    def __del__(self):\n",
    "        del self.model\n",
    "        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBdkgibORzyh"
   },
   "source": [
    "### Entrenando el modelo\n",
    "\n",
    "Crea una función que nos permita crear el modelo en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--x-RSJbeUdB"
   },
   "outputs": [],
   "source": [
    "# TODO: Entrena el modelo\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnqgYFqiSUSt"
   },
   "source": [
    "# ¡ENHORABUENA! Has completado la práctica de auto-aprendizaje.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7_autoaprendizaje.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AA2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
