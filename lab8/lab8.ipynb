{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8_generativos.ipynb","provenance":[{"file_id":"11ZwhCdoEq5exee9R6e86ONpfSw5Vv5zl","timestamp":1643284366812},{"file_id":"10sFXpiPDg5nkstFJH9pKWAk9GFwhoaf5","timestamp":1642959425848},{"file_id":"1PtNR7npOVBVixG2sEepX-b1l754jqWGg","timestamp":1627402726329}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"57knM8jrYZ2t"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eirasf/GCED-AA3/blob/main/lab8/lab8.ipynb)\n","\n","# Práctica 8: Modelos generativos\n","\n","## Pre-requisitos\n","\n","### Instalar paquetes\n","\n","Si la práctica requiere algún paquete de Python, habrá que incluir una celda en la que se instalen. Si usamos un paquete que se ha utilizado en prácticas anteriores, podríamos dar por supuesto que está instalado pero no cuesta nada satisfacer todas las dependencias en la propia práctica para reducir las dependencias entre ellas.\n","\n","### NOTA: En <font color='red'>Google Colab</font> hay que instalar los paquetes EN CADA EJECUCIÓN"]},{"cell_type":"code","metadata":{"id":"LkaimNJfYZ2w"},"source":["# Ejemplo de instalación de tensorflow 2.0\n","#%tensorflow_version 2.x\n","# !pip3 install tensorflow  # NECESARIO SOLO SI SE EJECUTA EN LOCAL\n","import tensorflow as tf\n","\n","# Hacemos los imports que sean necesarios\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOch-CnwQttl"},"source":["# Modelos generativos sobre MNIST\n","\n","Lo primero que tenemos que hacer es cargar el dataset."]},{"cell_type":"code","metadata":{"id":"1gXdWDBIEKel"},"source":["labeled_data = 0.01 # Vamos a usar el etiquetado de sólo el 1% de los datos\n","np.random.seed(42)\n","\n","(x_train, y_train), (x_test, y_test), = tf.keras.datasets.mnist.load_data()\n","\n","indexes = np.arange(len(x_train))\n","np.random.shuffle(indexes)\n","ntrain_data = int(labeled_data*len(x_train))\n","unlabeled_train = x_train[ntrain_data:]\n","x_train = x_train[:ntrain_data]\n","y_train = y_train[:ntrain_data]"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Haz el preprocesado que necesites aquí (si lo necesitas)\n","None"],"metadata":{"id":"8XsZIqV8TmSc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wkaCDOGapMyl"},"source":["## Modelo generativo\n","\n","Vamos a crear nuestro propio modelo generativo. En clase de teoría has visto muchas versiones distintas:\n","\n","1. Mezcla de distribuciones de Gaussianas (GMM)\n","1. Mezcla de distribuciones multinomiales (Naive Bayes)\n","1. Modelos de Markov ocultos (HMM)\n","\n","Tal y como se os apunta en teoría, los modelos generativos abordan un problema más general, y aprenden realmente cómo se estructuran y distribuyen los datos de entrada. \n","\n","En nuestro caso, vamos a distribuír los datos de entrada mediante el uso de **Autoencoders**. "]},{"cell_type":"markdown","source":["# Autoencoders\n","\n","El autoencoder es un tipo de red que se utiliza para aprender codificaciones eficientes de datos sin etiquetar (lo que se conoce como aprendizaje no supervisado). Es una red que tiene el mismo tamaño en la entrada como en la salida, puesto que el objetivo de la red es reconstruír la entrada con la menor pérdida posible.\n","\n","Si lo que hacemos es reconstruír la entrada, ¿qué sentido tiene el usar la red? Habitualmente, **la red consta, a su mitad, de una capa con menos elementos que los datos de entrada**. Por tanto, al reconstruír los datos de la entrada a la salida, en esa capa tendremos una versión *comprimida* de la entrada, que contendrá la mayor parte de su información.\n","\n","Por tanto, podemos dividir un autoencoder en 3 secciones diferentes, tal y como se ve en la siguiente figura:\n","\n","![](https://drive.google.com/uc?export=view&id=1yxkKZV0J0YplQAGPGJxQ2Z80Ad6L94eu)\n","\n","1. **Encoder:** es la parte inicial de la red, encargada de comprimir los datos de la entrada.\n","1. **Code:** es la salida del encoder, contiene la versión *comprimida* de los datos de entrada.\n","1. **Decoder:** se encarga de, partiendo de la salida del *Encoder*, reconstruír la red."],"metadata":{"id":"Pxf_lSC1HsYh"}},{"cell_type":"markdown","source":["## Crea tu propio Autoencoder\n","\n","El diseño del autoencoder es libre (capas densas, convolucionales, ...), puedes crearlo como quieras. **El único requisito es que tiene que mantener los nombres (y parámetros) de las funciones descritas abajo.**"],"metadata":{"id":"7-mBCsDXJX3M"}},{"cell_type":"code","source":["# TODO: crea tu propio autoencoder\n","\n","class MiAutoencoder:\n","\n","    def __init__(self, input_shape):\n","        # TODO : define el modelo y compílalo\n","        None\n","    \n","    def fit(self, X, y=None, sample_weight=None):\n","        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras\n","        None\n","\n","    def get_encoded_data(self, X):\n","        # TODO: devuelve la salida del encoder (code)\n","        None\n","        \n","    def __del__(self):\n","        # elimina todos los modelos que hayas creado\n","        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"],"metadata":{"id":"M95R6t1pJW3f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Crea tu propio Clasificador\n","\n","El diseño del clasificador es libre, pero recuerda que tiene que ser simple (máximo dos capas). **El único requisito es que tiene que mantener los nombres (y parámetros) de las funciones descritas abajo.**"],"metadata":{"id":"6tt0L2yCMdmb"}},{"cell_type":"code","source":["# TODO: crea tu propio clasificador\n","\n","class MiClasificador:\n","\n","    def __init__(self):\n","        # TODO : define el modelo y compílalo\n","        None\n","    \n","    def fit(self, X, y, sample_weight=None):\n","        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras\n","        None\n","\n","    def predict(self, X):\n","        # TODO: devuelve la clase ganadora\n","        None\n","    \n","    def predict_proba(self, X):\n","        None\n","    \n","    def score(self, X, y):\n","        None\n","\n","    def __del__(self):\n","        # elimina todos los modelos que hayas creado\n","        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"],"metadata":{"id":"1mh0yzbKMuhk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Entrenamiendo del modelo sin supervisar\n","\n","Primero de todo, a modo de comparación, vamos "],"metadata":{"id":"NtbZEJdJQmAg"}},{"cell_type":"markdown","source":["### Entrenamiendo del modelo semisupervisado\n","\n","El entrenamiento del sistema semisupervisado se realiza en dos pasos.\n","\n","1. Se entrena el autoencoder con todos los datos (etiquetados y sin etiquetar).\n","1. Se entrena un clasificador simple (una o dos capas), teniendo como entrada la salida del encoder (**code**) de los datos etiquetados."],"metadata":{"id":"w1-v4D6VH3Qq"}},{"cell_type":"markdown","source":["<font color='red'>NOTA:</font> para entrenar (y predecir) vamos a utilizar los nombres de las funciones que hemos definido en el autoencoder y en el clasificador."],"metadata":{"id":"vqT2nuCspfE_"}},{"cell_type":"code","metadata":{"id":"5xjcLa21EKen"},"source":["# TODO: implementa el algoritmo semisupervised_training.\n","\n","def semisupervised_training(autoencoder, classifier, x_train, y_train, unlabeled_data):\n","    None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Entrenamos nuestro modelo\n","\n","Usa lo hecho anteriormente para entrenar tu clasificador de una manera semi-supervisada."],"metadata":{"id":"qjFXe6EiYfRg"}},{"cell_type":"code","source":["# Crea tu autoencoder y tu clasificador\n","None"],"metadata":{"id":"lNC1s2Wmqx4x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Entrena tu modelo\n","None"],"metadata":{"id":"hN2zd3DEYnKI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Obtén la precisión sobre el conjunto de test\n","pred_data = autoencoder.get_encoded_data(x_test)\n","print('Test accuracy :', classifier.score(pred_data, y_test))"],"metadata":{"id":"n5tS8_SKOngm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Mejorando el código\n","\n","nuestro modelo actual requiere de dos pasos para entrenarse, pero podría realizarse en un único paso si **creamos un modelo con las dos salidas (autoencoder y clasificador)**. \n","\n","Para ello, hay que tener en cuenta que, en los datos sin etiquetar, su contribución al clasificador debería ser nula.\n","\n","\n","### TRABAJO: Crea el nuevo modelo y modifica la función semisupervised_training para tener en cuenta todos los puntos mencionados anteriormente"],"metadata":{"id":"MbUKp14pPsrp"}},{"cell_type":"code","source":["# TODO: crea el nuevo modelo\n","\n","# TODO: crea tu propio clasificador\n","\n","class MiClasificadorSemisupervisado:\n","\n","    def __init__(self, input_shape):\n","        # TODO : define el modelo y compílalo\n","        None\n","    \n","    def fit(self, X, y, unlabeled_data):\n","        # TODO: entrena el modelo. Escoge el tamaño de batch y el número de epochs que quieras, y define bien el sample_weight\n","        None\n","\n","    def predict(self, X):\n","        # TODO: devuelve la clase ganadora del clasificador\n","        None\n","    \n","    def predict_proba(self, X):\n","        # TODO: devuelve la probabilidad del clasificador\n","        None\n","    \n","    def score(self, X, y):\n","        None\n","\n","    def __del__(self):\n","        # elimina todos los modelos que hayas creado\n","        tf.keras.backend.clear_session() # Necesario para liberar la memoria en GPU"],"metadata":{"id":"xS3JLE37SqrG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: reescribe la función semisupervised_training para incorporar las mejoras mencionadas anteriormente\n","\n","def semisupervised_training_v2(model, x_train, y_train, unlabeled_data):\n","    None"],"metadata":{"id":"7eF_9LMeZ2J2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Crea y entrena tu clasificador\n","None"],"metadata":{"id":"YbqC0inexwHp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Obtén la precisión sobre el conjunto de test\n","print('Test accuracy :', model.score(x_test, y_test))"],"metadata":{"id":"JSVVW8fZXWGs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ¡ENHORABUENA! Has completado la práctica de modelos generativos.\n"],"metadata":{"id":"qnqgYFqiSUSt"}},{"cell_type":"markdown","source":["# Trabajo extra\n","\n","¿Has probado a hacer el autoencoder totalmente convolucional? Para el *decoder* puedes usar las funciones [UpSampling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D) o [Conv2DTranspose](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose)."],"metadata":{"id":"vEZfd7iVX94s"}}]}
